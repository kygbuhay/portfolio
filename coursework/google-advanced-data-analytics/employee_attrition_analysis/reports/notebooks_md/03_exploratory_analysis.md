# 03 Exploratory Analysis

**Exported from:** `03_exploratory_analysis.ipynb`
**Generated:** 2025-10-04 17:09:01
**Project:** employee_attrition_analysis

---

# Employee Attrition Analysis ‚Äî 03: Exploratory Data Analysis

***Understanding patterns and distributions in the cleaned dataset to inform modeling strategy***

**Author:** Katherine Ygbuhay  
**Updated:** 2025-10-04  
**Stage:** 03 ‚Äî Exploratory Data Analysis  
**Runtime:** ~20 minutes  

## Objective

Explore the cleaned HR attrition dataset to identify patterns, trends, and relationships between variables that will inform feature engineering and model selection.

## Scope & Approach

- **Descriptive statistics** across all variables with focus on target class balance
- **Categorical analysis** of department and salary distributions  
- **Visual exploration** through histograms, boxplots, and correlation heatmaps
- **Pattern identification** for variables strongly associated with attrition

## Key Outputs

- EDA summary with key findings in `docs/notes/eda_summary.md`
- Correlation analysis revealing feature relationships
- Visual documentation of distributions and target patterns
- Data quality assessment confirming modeling readiness

## Prerequisites

- Cleaned employee dataset from `02_data_cleaning.ipynb`
- Data dictionary understanding from previous stage
- Visualization utilities from project's `src/viz_helpers`

---

## 1. Imports & Setup
```python
import os
os.environ["PORTFOLIO_PROJECT"] = "employee_attrition_analysis"

import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from src.bootstrap import setup_notebook
from src.viz_helpers import (
    pretty_label, adjust_xtick_labels, barplot_counts,
    hist_grid, boxplot_by_target, apply_plot_rc_defaults)

RAW_NAME  = "salifort_employee_attrition_raw.csv"
PROC_NAME = "salifort_employee_attrition_cleaned.csv"

P, df = setup_notebook(raw_filename=RAW_NAME, proc_filename=PROC_NAME, load="proc")
apply_plot_rc_defaults()   # bump font sizes once (before any plot)
```

    üé® Accessibility defaults applied (colorblind palette, high-contrast, safe colormap).
    ‚úÖ Accessibility defaults applied
    üìÅ Project root ‚Üí /home/admin/Documents/portfolio/coursework/google-advanced-data-analytics/employee_attrition_analysis
    ‚úÖ Loaded PROC: data/processed/salifort_employee_attrition_cleaned.csv | shape=(14999, 11)


## 2. Schema Confirmation
```python
print(f"‚úÖ {P.PROC.relative_to(P.ROOT)} | shape={df.shape}")
df.info()
```

    ‚úÖ data/processed/salifort_employee_attrition_cleaned.csv | shape=(14999, 11)
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14999 entries, 0 to 14998
    Data columns (total 11 columns):
     #   Column                 Non-Null Count  Dtype  
    ---  ------                 --------------  -----  
     0   satisfaction_level     14999 non-null  float64
     1   last_evaluation        14999 non-null  float64
     2   number_project         14999 non-null  int64  
     3   average_montly_hours   14999 non-null  int64  
     4   time_spend_company     14999 non-null  int64  
     5   Work_accident          14999 non-null  int64  
     6   left                   14999 non-null  int64  
     7   promotion_last_5years  14999 non-null  int64  
     8   Department             14999 non-null  object 
     9   salary                 14999 non-null  object 
     10  salary_level           14999 non-null  int64  
    dtypes: float64(2), int64(7), object(2)
    memory usage: 1.3+ MB


## 3. Descriptive Statistics
```python
# Numeric feature summary
df.describe().T
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>satisfaction_level</th>
      <td>14999.0</td>
      <td>0.612760</td>
      <td>0.248517</td>
      <td>0.09</td>
      <td>0.44</td>
      <td>0.64</td>
      <td>0.82</td>
      <td>0.99</td>
    </tr>
    <tr>
      <th>last_evaluation</th>
      <td>14999.0</td>
      <td>0.716252</td>
      <td>0.170873</td>
      <td>0.39</td>
      <td>0.56</td>
      <td>0.72</td>
      <td>0.87</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>number_project</th>
      <td>14999.0</td>
      <td>3.803054</td>
      <td>1.232592</td>
      <td>2.00</td>
      <td>3.00</td>
      <td>4.00</td>
      <td>5.00</td>
      <td>7.00</td>
    </tr>
    <tr>
      <th>average_montly_hours</th>
      <td>14999.0</td>
      <td>201.034802</td>
      <td>49.771459</td>
      <td>104.00</td>
      <td>156.00</td>
      <td>200.00</td>
      <td>245.00</td>
      <td>301.00</td>
    </tr>
    <tr>
      <th>time_spend_company</th>
      <td>14999.0</td>
      <td>3.498233</td>
      <td>1.460136</td>
      <td>2.00</td>
      <td>3.00</td>
      <td>3.00</td>
      <td>4.00</td>
      <td>10.00</td>
    </tr>
    <tr>
      <th>Work_accident</th>
      <td>14999.0</td>
      <td>0.144610</td>
      <td>0.351719</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>left</th>
      <td>14999.0</td>
      <td>0.238083</td>
      <td>0.425924</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>promotion_last_5years</th>
      <td>14999.0</td>
      <td>0.021268</td>
      <td>0.144281</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>salary_level</th>
      <td>14999.0</td>
      <td>0.594706</td>
      <td>0.637183</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>1.00</td>
      <td>2.00</td>
    </tr>
  </tbody>
</table>
</div>



## 4. Target Class Balance
```python
# Distribution of attrition target
ax = barplot_counts(df["left"], "Class Balance: Attrition (left)")
plt.xlabel("Attrition (0=stay, 1=left)"); plt.show()
```


    
![png](output_8_0.png)
    


## 5. Categorical Breakdowns
```python
# Resolve column names whether raw or encoded
dept_col = "department" if "department" in df.columns else ("Department" if "Department" in df.columns else "department_code")
sal_col  = "salary"     if "salary" in df.columns     else "salary_level"

barplot_counts(df[dept_col], "Department Distribution"); plt.show()
barplot_counts(df[sal_col],  "Salary Distribution");     plt.show()
```


    
![png](output_10_0.png)
    



    
![png](output_10_1.png)
    


## 6. Visualizations
```python
hist_grid(df)  # 2 per row, big suptitle, Title Case subplot titles

boxplot_by_target(
    df,
    feature_cols=["satisfaction_level", "last_evaluation", "average_montly_hours", "time_spend_company"],
    target="left"
)
```


    
![png](output_12_0.png)
    



    
![png](output_12_1.png)
    



    
![png](output_12_2.png)
    



    
![png](output_12_3.png)
    



    
![png](output_12_4.png)
    


## 7. Correlation Heatmap
```python
from src.viz_helpers import adjust_heatmap_labels

plt.figure(figsize=(10, 6))
corr = df.corr(numeric_only=True)
ax = sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
adjust_heatmap_labels(ax, rotation_x=45, rotation_y=0)  # <<< here
plt.tight_layout()
plt.show()
```


    
![png](output_14_0.png)
    


## 8. Save Notes & Assessment Check
```python
from src.bootstrap import write_notes

notes_md = "\n".join([
    "# EDA Summary",
    f"- Dataset: {df.shape[0]} rows √ó {df.shape[1]} cols",
    "- Class balance: checked",
    "- Department & salary distributions: plotted",
    "- Numeric distributions: histograms + boxplots",
    "- Correlations: heatmap",
])

write_notes(P, "eda_summary.md", notes_md)

# Assessment
checks = {
    "processed_exists": P.PROC.exists(),
    "no_missing": int(df.isna().sum().sum()) == 0,
}
print("Checks:", checks)
assert all(checks.values()), "‚ùå Assessment failed."
print("‚úÖ Assessment passed: dataset representative, high-quality, minimal missingness.")
```

    üìù Wrote notes ‚Üí docs/notes/eda_summary.md
    Checks: {'processed_exists': True, 'no_missing': True}
    ‚úÖ Assessment passed: dataset representative, high-quality, minimal missingness.


---

## EDA Summary

- **Dataset:** 14,999 rows √ó 11 columns (processed). :contentReference[oaicite:0]{index=0}
- **Missingness:** None detected in the processed dataset.
- **Class Balance (`left`):** Imbalanced toward **0 = stay**; proceed with metrics beyond accuracy (e.g., recall/PR AUC).
- **Categorical Distributions:** 
  - **Department:** Sales is the largest; others (technical, support, IT, etc.) follow with smaller shares.
  - **Salary:** Skewed toward **low** and **medium** bands; few **high**.
- **Numeric Distributions:** Clear spread across satisfaction, evaluation, monthly hours, tenure; no extreme collinearity observed.
- **By-Attrition Patterns (boxplots):** Leavers tend to show **lower satisfaction**; other features show differences worth validating in modeling.
- **Correlations:** No severe multicollinearity among numeric features; proceed safely with linear and tree-based baselines.
- **Artifacts:** Notes saved to `docs/notes/eda_summary.md`; figures rendered inline.
